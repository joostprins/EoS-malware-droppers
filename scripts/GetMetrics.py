import csv
import os
import socket
import re
from datetime import datetime
import geoip2.database
import tldextract

countryReader = geoip2.database.Reader('./GeoLite2-Country.mmdb')

urlRegex = re.compile('(https?://)?([^/]+)')

droppers = []
counter = 0
domainMap = {}

file = "..\\data\\cleanMX_viruses2014_Sep" # needs to be done for each file

with open(os.path.join(os.getcwd(), file), 'r') as csvFile:
    reader = csv.reader(csvFile)
    firstRow = True
    for _,dateTime,url in reader:
        if firstRow:
            firstRow = False
            continue
        if "firsttime" in dateTime:
            break
        try:
            (http,domain) = urlRegex.match(url).groups()
            if "www." in domain:
                domain = domain[4:]
        except:
            continue
        try:
            if domain not in domainMap:
                ip = socket.gethostbyname(domain)
                domainMap[domain] = ip
            else:
                ip = domainMap[domain]
        except Exception as e:
            ip = "unknown"
        try:
            country = countryReader.country(ip).country.name
        except:
            country = "unknown"
        try:
            tld = tldextract.extract(domain).suffix
            if len(tld) < 1:
                tld = "unknown"
        except:
            tld = "unknown"
        droppers.append([dateTime, url, domain, tld, ip, country])
        counter = counter + 1
        if counter % 1000 == 0:
            print(counter)
csvFile.close()

sortedDroppers = sorted(
    droppers,
    key=lambda x: datetime.strptime(x[0], '%Y-%m-%d %H:%M:%S')
)

csvColumns = ['dateTime','url','domain','tld','ip','country']
sortedFile = file + "_ips"
with open(sortedFile, 'w') as csvFile:
    writer = csv.writer(csvFile, delimiter=',',lineterminator='\n')
    writer.writerow(csvColumns)
    for row in sortedDroppers:
        writer.writerow([row[0],row[1],row[2],row[3],row[4],row[5]])