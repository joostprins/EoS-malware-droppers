import csv
import os
import re
import socket

import geoip2.database
import tldextract


def read_file_length(file_to_process):
    count = 0
    thefile = open(file_to_process, 'rb')
    while 1:
        buffer = thefile.read(8192 * 1024)
        if not buffer: break
        count += buffer.count(b'\n')
    thefile.close()
    return count


country_reader = geoip2.database.Reader(os.path.join("..", "data", "GeoLite2-Country.mmdb"))

url_regex = re.compile("(https?://)?([^/]+)")

counter = 0
domain_map = {}

file_name = "cleanMX_viruses2014_Apr"  # needs to be done for each file

file = os.path.join("..", "data", file_name)
csv_file = open(os.path.join(os.getcwd(), file), "r")

csv_columns = ["dateTime", "url", "domain", "tld", "ip", "country"]
sorted_file = file + "_ips"

skip_n_lines = 0
if os.path.exists(sorted_file):
    skip_n_lines = read_file_length(sorted_file)

sorted_csv_file = open(sorted_file, "a")

writer = csv.writer(sorted_csv_file, delimiter=",", lineterminator="\n")
first_row = True
if skip_n_lines == 0:
    writer.writerow(csv_columns)
    first_row = False


reader = csv.reader(csv_file)
for _, date_time, url in reader:
    if first_row:
        first_row = False
        continue
    counter = counter + 1
    if counter < skip_n_lines:
        continue
    print(counter)
    print(skip_n_lines)
    if "firsttime" in date_time:
        break
    try:
        (http, domain) = url_regex.match(url).groups()
        if "www." in domain:
            domain = domain[4:]
    except:
        continue
    try:
        if domain not in domain_map:
            ip = socket.gethostbyname(domain)
            domain_map[domain] = ip
        else:
            ip = domain_map[domain]
    except Exception as e:
        ip = "unknown"
    try:
        country = country_reader.country(ip).country.name
    except:
        country = "unknown"
    try:
        tld = tldextract.extract(domain).suffix
        if len(tld) < 1:
            tld = "unknown"
    except:
        tld = "unknown"
    writer.writerow([date_time, url, domain, tld, ip, country])
    if counter % 1000 == 0:
        print(counter)
sorted_csv_file.close()
